{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PedroPepeu/CUDA-pratical-class/blob/main/CUDA_Pratical_Activity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "!nvcc --version\n",
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rK0n1dOi7Vi_",
        "outputId": "e59c4bce-f529-434a-cb89-c50a8f81cb41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.12\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpsjj68za0\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify GPU access\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g55zXHoF3agX",
        "outputId": "68f64dfd-fe20-4a8b-e8d8-92eb76945404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May 21 14:45:17 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg496tHG8xhm",
        "outputId": "7ab8e694-2f84-4b18-c6f3-98df05f43126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_ops.cu\n",
        "#include <stdio.h>  // Para funções de entrada/saída (printf)\n",
        "#include <stdlib.h> // Para funções de entrada/saída (printf)\n",
        "#include <math.h>   // Para funções matemáticas\n",
        "\n",
        "// CHECAGEM DE ERRO, CHAMA FUNÇAO VER SE DA ERRO MOSTRA LOG DE ERRO\n",
        "#define CHECK_CUDA_ERROR(call) \\\n",
        "do { \\\n",
        "    cudaError_t err = call; \\\n",
        "    if (err != cudaSuccess) { \\\n",
        "        printf(\"CUDA Error: %s:%d, %s\\n\", __FILE__, __LINE__, cudaGetErrorString(err)); \\\n",
        "        exit(EXIT_FAILURE); \\\n",
        "    } \\\n",
        "} while(0)\n",
        "\n",
        "// Kernel for vector addition\n",
        "__global__ void vectorAdd(float *a, float *b, float *result, int n) {\n",
        "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (i < n) {\n",
        "        result[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel for vector subtraction\n",
        "__global__ void vectorSub(float *a, float *b, float *result, int n) {\n",
        "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (i < n) {\n",
        "        result[i] = a[i] - b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel for vector multiplication\n",
        "__global__ void vectorMul(float *a, float *b, float *result, int n) {\n",
        "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (i < n) {\n",
        "        result[i] = a[i] * b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel for vector division\n",
        "__global__ void vectorDiv(float *a, float *b, float *result, int n) {\n",
        "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (i < n) {\n",
        "        if (b[i] != 0) {  // Avoid division by zero\n",
        "            result[i] = a[i] / b[i];\n",
        "        } else {\n",
        "            result[i] = 0;  // Or handle differently as needed\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "//Esta função imprime apenas os primeiros 5 elementos do vetor para não poluir a saída.\n",
        "void printVector(float *vec, int n, const char* name) {\n",
        "    printf(\"%s: [\", name);\n",
        "    for (int i = 0; i < (n < 5 ? n : 5); i++) {\n",
        "        printf(\"%.2f\", vec[i]);\n",
        "        if (i < (n < 5 ? n - 1 : 4)) printf(\", \");\n",
        "    }\n",
        "    if (n > 5) printf(\", ...\");\n",
        "    printf(\"]\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 10; // Tamanho do vetor\n",
        "    size_t size = n * sizeof(float); // Tamanho em bytes\n",
        "\n",
        "    // Host vectors\n",
        "    float *h_a = (float *)malloc(size); // Vetor A\n",
        "    float *h_b = (float *)malloc(size); // Vetor B\n",
        "    float *h_result = (float *)malloc(size); // Vetor resultado\n",
        "\n",
        "    if (h_a == NULL || h_b == NULL || h_result == NULL) {\n",
        "        printf(\"Host memory allocation failed\\n\");\n",
        "        return -1;\n",
        "    }\n",
        "\n",
        "    // Initialize vectors\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_a[i] = i + 1.0;       // [1, 2, 3, ...]\n",
        "        h_b[i] = (i + 1) * 2.0;  // [2, 4, 6, ...]\n",
        "    }\n",
        "\n",
        "    // Alocação de Memória na GPU: d_ prefixo indica memória na GPU (device)\n",
        "    float *d_a, *d_b, *d_result;\n",
        "    CHECK_CUDA_ERROR(cudaMalloc(&d_a, size));\n",
        "    CHECK_CUDA_ERROR(cudaMalloc(&d_b, size));\n",
        "    CHECK_CUDA_ERROR(cudaMalloc(&d_result, size));\n",
        "\n",
        "    //  Cópia de Dados para a GPU\n",
        "    CHECK_CUDA_ERROR(cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice));\n",
        "    CHECK_CUDA_ERROR(cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // Configuração de Execução\n",
        "    int threadsPerBlock = 256; // Threads por bloco\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;// Número de blocos\n",
        "\n",
        "    // Perform each operation and print results\n",
        "    printf(\"Vector Operations:\\n\");\n",
        "    printVector(h_a, n, \"A\");\n",
        "    printVector(h_b, n, \"B\");\n",
        "\n",
        "    // Addition\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_result, n);\n",
        "    CHECK_CUDA_ERROR(cudaGetLastError());\n",
        "    CHECK_CUDA_ERROR(cudaDeviceSynchronize());\n",
        "    CHECK_CUDA_ERROR(cudaMemcpy(h_result, d_result, size, cudaMemcpyDeviceToHost));\n",
        "    printVector(h_result, n, \"A + B\");\n",
        "\n",
        "    // Subtraction\n",
        "    vectorSub<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_result, n);\n",
        "    CHECK_CUDA_ERROR(cudaGetLastError());\n",
        "    CHECK_CUDA_ERROR(cudaDeviceSynchronize());\n",
        "    CHECK_CUDA_ERROR(cudaMemcpy(h_result, d_result, size, cudaMemcpyDeviceToHost));\n",
        "    printVector(h_result, n, \"A - B\");\n",
        "\n",
        "    // Multiplication\n",
        "    vectorMul<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_result, n);\n",
        "    CHECK_CUDA_ERROR(cudaGetLastError());\n",
        "    CHECK_CUDA_ERROR(cudaDeviceSynchronize());\n",
        "    CHECK_CUDA_ERROR(cudaMemcpy(h_result, d_result, size, cudaMemcpyDeviceToHost));\n",
        "    printVector(h_result, n, \"A * B\");\n",
        "\n",
        "    // Division\n",
        "    vectorDiv<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_result, n);\n",
        "    CHECK_CUDA_ERROR(cudaGetLastError());\n",
        "    CHECK_CUDA_ERROR(cudaDeviceSynchronize());\n",
        "    CHECK_CUDA_ERROR(cudaMemcpy(h_result, d_result, size, cudaMemcpyDeviceToHost));\n",
        "    printVector(h_result, n, \"A / B\");\n",
        "\n",
        "    // Cleanup:Libera toda a memória alocada, tanto na CPU quanto na GPU.\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_result);\n",
        "    CHECK_CUDA_ERROR(cudaFree(d_a));\n",
        "    CHECK_CUDA_ERROR(cudaFree(d_b));\n",
        "    CHECK_CUDA_ERROR(cudaFree(d_result));\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgvgnsTe7BBA",
        "outputId": "677a233a-3d2d-44a6-d404-94fc78c96314"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_ops.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vector_ops.cu -o vector_ops -arch=sm_75\n",
        "!./vector_ops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwB86so47JhS",
        "outputId": "cb513601-0f04-4e6c-d936-ca72f1aaa728"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector Operations:\n",
            "A: [1.00, 2.00, 3.00, 4.00, 5.00, ...]\n",
            "B: [2.00, 4.00, 6.00, 8.00, 10.00, ...]\n",
            "A + B: [3.00, 6.00, 9.00, 12.00, 15.00, ...]\n",
            "A - B: [-1.00, -2.00, -3.00, -4.00, -5.00, ...]\n",
            "A * B: [2.00, 8.00, 18.00, 32.00, 50.00, ...]\n",
            "A / B: [0.50, 0.50, 0.50, 0.50, 0.50, ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile custom_formula.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "/*\n",
        " * STUDENT TASK: Implement your custom formula here\n",
        " *\n",
        " * The formula should use elements from both vectors a and b\n",
        " * Example formulas you could implement:\n",
        " * 1. (a + b) / 2         (Average)\n",
        " * 2. a² + b²             (Sum of squares)\n",
        " * 3. sqrt(a² + b²)       (Magnitude)\n",
        " * 4. a * b + a + b       (Custom polynomial)\n",
        " *\n",
        " * Choose one or create your own!\n",
        " */\n",
        "__global__ void customFormula(float *a, float *b, float *result, int n) {\n",
        "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    if (i < n) {\n",
        "        // STUDENT TODO: Implement your formula here\n",
        "        // Example: result[i] = (a[i] + b[i]) / 2.0f;\n",
        "        result[i] = 0.0f; // Change this!\n",
        "    }\n",
        "}\n",
        "\n",
        "void printVector(float *vec, int n) {\n",
        "    printf(\"[\");\n",
        "    for (int i = 0; i < min(n, 5); i++) {\n",
        "        printf(\"%.2f\", vec[i]);\n",
        "        if (i < min(n, 5) - 1) printf(\", \");\n",
        "    }\n",
        "    if (n > 5) printf(\", ...\");\n",
        "    printf(\"]\\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 10; // Vector size\n",
        "    size_t size = n * sizeof(float);\n",
        "\n",
        "    // Host vectors\n",
        "    float *h_a = (float *)malloc(size);\n",
        "    float *h_b = (float *)malloc(size);\n",
        "    float *h_result = (float *)malloc(size);\n",
        "\n",
        "    // Initialize vectors\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_a[i] = i + 1.0f;       // [1, 2, 3, ...]\n",
        "        h_b[i] = (i + 1) * 2.0f;  // [2, 4, 6, ...]\n",
        "    }\n",
        "\n",
        "    // Device vectors\n",
        "    float *d_a, *d_b, *d_result;\n",
        "    cudaMalloc(&d_a, size);\n",
        "    cudaMalloc(&d_b, size);\n",
        "    cudaMalloc(&d_result, size);\n",
        "\n",
        "    // Copy to device\n",
        "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch configuration\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // Run custom formula\n",
        "    customFormula<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_result, n);\n",
        "    cudaMemcpy(h_result, d_result, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print results\n",
        "    printf(\"Vector A: \");\n",
        "    printVector(h_a, n);\n",
        "    printf(\"Vector B: \");\n",
        "    printVector(h_b, n);\n",
        "    printf(\"Custom formula result: \");\n",
        "    printVector(h_result, n);\n",
        "\n",
        "    // Cleanup\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_result);\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_result);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "bhsRRcpH7EIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f46346d6-e2af-4398-9806-0381ef9d99c8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing custom_formula.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc custom_formula.cu -o custom_formula\n",
        "!./custom_formula"
      ],
      "metadata": {
        "id": "bxSibMPt7GW2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}